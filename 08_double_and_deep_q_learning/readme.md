Prework
======

Introductory
-------

- Double Q-Learning
    - Stanford CS234: Reinforcement Learning | Lecture 4 - Model Free Control
        + Starting at 1:15 - [Video](https://www.youtube.com/watch?v=j080VBVGkfQ&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=4)
         + [Slides & Draft lecture notes](http://web.stanford.edu/class/cs234/schedule.html)

Required
------

+ Deep Q-learning from "Spinning Up in Deep RL Workshop" by OpenAI from 1:48 to 2:25
    + [video](https://youtu.be/fdY7dt3ijgY?t=6482)
    + [slides start at #48](https://github.com/openai/spinningup-workshop/blob/master/rl_intro/rl_intro.pdf)
- [Play with Q-learning demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html)
- [Deep Reinforcement Learning and the Deadly Triad](https://arxiv.org/abs/1812.02648)
- [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461https://arxiv.org/abs/1509.06461)


Challenge
-----

- As a class, we are are skipping the following Stanford lectures. They are mostly research-oriented. You are welcome to watch it on your own.
    - Lecture 7 - Imitation Learning 
    - Lecture 8 - Policy Gradient I
    - Lecture 9 - Policy Gradient II
    - Lecture 10 - Policy Gradient III & Midterm Review 
